## Identifying research gaps

Detection and diagnosis rely on clinicians[^2] searching for abnormalities in medical images.
Across the many ways to acquire images (from light microscopy to magnetic resonance) and present those images (e.g., via glass slides or computer workstations), clinicians are confronted with similar perceptual and cognitive challenges.
Clinicians are tasked with bringing to bear a vast amount of medical knowledge, together with contextual information about the patient (e.g., referring physician's information, prior report, prior medical history, genomics information) in order to interpret highly complex and variable images quickly and accurately.

This is a challenging endeavor.
Clinicians face many difficulties, from information overload to repeated interruptions to clinician burnout, that in turn are closely associated with health care quality, patient safety, and financial burdens on practices [@doi:10.1001/jamainternmed.2018.3713; @doi:10.1001/jamainternmed.2017.4340; @doi:10/ckcn8j].
Even under ideal circumstances, human observers are bound to make mistakes.
Errors, both false positives and false negatives, are a reality in both radiology [@doi:10.2214/AJR.06.1270; @doi:10.1016/j.clon.2016.05.003; @doi:10.1016/j.urolonc.2015.04.005] and pathology practice [@doi:10.1002/cncr.21431].
The majority of diagnostic errors in radiology can be traced to perceptual and cognitive factors [@doi:10.2214/ajr.165.4.7676967; @raw:Smith-1967].
The same is probably true in pathology, though there is much less research in this area [@doi:10.1002/cncr.21431] .
Improving the accuracy of diagnosis requires an understanding of the perceptual and cognitive mechanisms underlying the performance of clinicians.
Additionally, cognitive and perceptual principles and approaches should be applied to address issues concerning clinicians' work environment and well-being.

What research should we encourage in order to improve clinicians' diagnostic accuracy, work environment, and well-being? The first challenge for the Think Tank participants was to identify the research gaps and critical unsolved problems in pathology and radiology, from the perspective of clinicians.
The primary challenges identified by the clinicians were information overload and integrating large amounts of information from various sources.

For example, the transition from the analog to the digital eras has meant a qualitative change in the nature of the image interpretation problem.
A radiologist scrutinizing a single chest X-ray for a lung nodule is trying to extract a target with a very low signal:noise ratio (SNR) from a single image.
The same radiologist reading a chest CT is searching for a target with a fairly high SNR in a scan comprising thousands of images (slices).
In addition, the radiologist must now incorporate into their decisions information from outside sources, such as electronic health records and genetic panels, that may not have been available in the past.
Furthermore, the decisions that clinicians have to make have gotten more complex as precision medicine has advanced.
A pathologist now might have to indicate not just whether something is a tumor or not, but if the tumor is "hot" or "cold", likely to be responsive or non-responsive.
The cognitive capacity of the clinician, in contrast, has not changed, and the time pressure has only gotten worse.

What are the effects of information overload on medical decision making and decision quality? Are there technical solutions or decision-making aids or strategies that could be used to efficiently integrate complex information? For example, psychologically distancing oneself from information has been shown to improve non-medical decision-making [@doi:10.1037/a0030730].
What is the applicability of decision strategies to real world practice? The cognitive and perceptual challenges of the clinicians' role, and the implications for practice, are poorly understood at present.

Task shifting was another topic identified by the Think Tank participants.
Interruptions and distractions from a variety of sources (e.g., texts, email, pager, colleagues, telephone) may lead clinicians to miss or fail to report important findings.
Another form of task shifting occurs within the workflow, when clinicians move from case to case, from organ to organ, and from image modality to image modality.
There is no research on whether task shifting during medical image interpretation creates adverse sequential consequences and/or how to mitigate any such effects.

As one might expect from the above descriptions, the workload for clinicians has increased, and physical and mental fatigue of clinicians are at unprecedented levels, contributing to both perceptual and interpretive errors.
Fatigue can manifest as attention errors, such as when a clinician scrolls too quickly through multi-slice or volumetric images. Having merely displayed all the slices on screen can produce the false impression that the clinician has sufficiently viewed the case.
Additional errors can result from lack of focus, getting easily distracted, and/or failing to record what is perceived.
These errors caused by physical and mental fatigue become more apparent at the end of the day.
Multiple studies have reported a decrease in detection accuracy due to fatigue [for a review, see @doi:10.1016/j.jacr.2016.10.009] but translational research needs to be conducted on possible interventions that could mitigate fatigue effects in real world practice.

Interpretative errors can arise from a variety of sources.
In radiology, several categories of tumors can be difficult to interpret, such as when there is a subtle gradient (i.e., when it is difficult to notice subtle changes or new lesions) from benign to malignant tumors, malignant to benign tumors, and when benign tumors mimic malignant tumors.
Additionally, it is also often difficult to interpret or connect two disparate findings (e.g., adrenal nodule with a lung mass), and the clinician ends up failing to link findings and report a complete picture.
Research should focus on understanding the basic science behind these perceptual and cognitive problems as a first step to developing techniques for mitigating interpretation difficulty.

Artificial intelligence (AI) tools are often proposed as a solution to many of the challenges facing clinicians.
However, there is a mismatch between what clinicians need from AI and how AI is typically developed.
In news reports, AI solutions are often pitched as "outperforming" the clinician, implying that AI systems are on the cusp of replacing the clinician [@url:www.newyorker.com/magazine/2017/04/03/ai-versus-md], or at least serving as an equivalent reader [@doi:10.1038/s41586-019-1799-6].
This stems from an incomplete picture of the clinicians' job.
First, an AI that performs well in a laboratory setting may not perform as well, once deployed to the field.
Second, an AI would need to be virtually perfect before it would be accepted as a replacement for a human as the ultimate decision maker.
Finally, humans observers are more than collections of image-interpretation routines.
The clinician's role also requires many non-interpretative functions, such as interacting with patient-facing clinicians or dealing with patient responses to contrast, that AI cannot yet perform.

A better approach would be to consider AI to be a talented assistant, making the clinician’s work easier by automating aspects of the data reduction process and presenting information that can aid the clinician’s decision process.
This role, of AI as a talented assistant, has already gained some clinical utility in areas, such as interpretation of pap smears, viewing cancer screening mammograms, as well as other tasks, such as looking for medical errors in prescriptions.
It is likely that AI can also make constructive contributions to institutional operations and quality assurance efforts.

A useful framework to stimulate our thinking is the developing concept of the “diagnostic cockpit of the future.” As described by Krupinski et al., [-@doi:10.1016/j.acra.2018.11.017] the diagnostic concept includes a set of tools to “aggregate, organize, and simplify medical imaging results and patient-centric clinical data.”
The aggregation of multiparametric data is typically not a strength of the human observer, but could well be a strength of the computer.
The diagnostic cockpit metaphor suggests that we need to design AI tools so that humans can make the best use of them.
During the Second World War, thousands of B-17 bombers crashed upon landing, without any sign of mechanical failure.
Psychologists Paul Fitts and Alphonse Chapanis noticed that the controls for the landing gear and for the flaps were identical, so that pilots were often mistaking one for the other.
By changing the shape of the controls, they were able to avert many crashes [@url:www.wired.com/story/how-dumb-design-wwii-plane-led-macintosh/].
Similarly, ensuring that the diagnostic cockpit does not create new errors will require an understanding of human cognition as well as engineering.
Diagnostic AI must be developed within a broad interdisciplinary context.
Clinical, perceptual, and cognitive perspectives are all needed in the development process, rather than treated as an afterthought.

[^2]: Here we will use the word "clinicians" to refer to anyone tasked with reading a medical image. The typical clinician in this sense will be a radiologist or pathologist, but the term should be understood to include many other specialties such as nuclear medicine or dermatology, as well as non-specialists who read images as part of their practice.
