## Addressing clinical questions through perceptual research

There's an old science joke that goes something like this: A dairy farmer is looking for ways to increase the output of his cows, as cheaply as possible.
He consults an agronomist, who recommends changes to the feedstock and new equipment which will require major investments. He turns to a biologist, who suggests hormone treatments that will be cheaper, but still involve an outlay of more money than he wants to spend.
Finally, he turns to a physicist, who promises a free solution. He eagerly asks her to explain her idea.
She begins, "First, assume a spherical cow with radius *r* and mass *m*, uniformly emitting milk in all directions..."

To many clinicians, perceptual research on medical image interpretation can sometimes seem like the equivalent of a spherical cow emitting milk in all directions.
Perceptual studies typically abstract away from the specificity and messiness of the clinical reading context in order to gain experimental control.
Complex stimuli are simplified, narrative reports are replaced with binary responses, clinical history is absent, and the life-and-death stakes of the clinic are removed.

Consider Wolfe et al.'s [@doi:10.1037/0096-3445.136.4.623] work on the effects of prevalence – the proportion of trials/cases that contain a target.
In their experiments, non-expert observers, drawn from the Cambridge, MA community, were asked to search for semi-transparent image of a tool, embedded in a noisy background with other non-tool objects.
The task was intended to be an approximation of the search for targets like cancerous lesions in mammograms or lung CTs or, for that matter, threats in carry-on baggage at the airport.
Obviously, such an experiment is not using medical images or medical experts as viewers.
Performance on the task has none of the consequence that could accompany errors in a clinical setting.

It would not be surprising if such factors lead to a certain skepticism in the clinician community about the value of perception research.
However, it is only by making such methodological choices that a researcher can reasonably expect to design a laboratory study of, in this case, the effects of target prevalence. Testing differences in performance at low prevalence (e.g. 2% of trials) and high prevalence (50%) requires thousands of trials for adequate statistical power.
Even if one curated a set of medical images for such a study, the chances of recruiting a dozen radiologists to read all those images is quite remote.
As experimental subjects, experts need to be reserved for relatively short, carefully crafted experiments. Basic studies require other methods.

As a consequence, there is a developing medical image perception paradigm that could be called “Reverse Translation”.
A researcher observes a problem in the clinic and abstracts out a basic question about the underlying cognitive and perceptual capabilities required. The researcher will then develop lab versions of the problem to study the basic science.
These studies will sometimes use observer models, undergraduate students, or other non-experts as they are more practical to use in lab studies as clinicians time is limited.
After many iterations of working out the basic science and once the researcher has a good working hypothesis, they can then go back to the clinical setting to test their hypothesis with a plausible, well-focused experiment.
In the case of the aforementioned work on prevalence, a substantial body of research using non-experts and controlled laboratory tasks has shown that observers become more conservative (in the signal detection theory sense of that word) and more likely to miss targets that would be found in a set of images with higher target prevalence [@doi:10.1111/jpr.12153].
Returning to the clinical sitting, this criterion shift has been shown to occur in both mammography [@doi:10.1371/journal.pone.0064366.s003], cytopathology [@doi:10.5858/arpa.2010-0739-OA], and now emerging with Coronavirus (COVID-19). Infectious diseases, compared to cancer, have shifting prevalence rates [@doi: 10.1016/j.tmaid.2020.101711]. Empirical work is needed to understand COVID-19 prevalence effects and within the context of cancer detection.
This reverse translation strategy faces several barriers.
One problem with this type of “use-inspired basic-research” [@doi:10.1186/s41235-016-0019-2; @raw:Stokes-1997] is that the problems that are being assessed may not be the critical problems that clinicians actually want answered.
We propose researchers strive to investigate problem that are clinically significant via closer collaboration between clinicians and basic researchers (discussed further, below).

Second, even if a good problem is identified, clinicians and peer reviewers can raise doubts about whether research done with non-expert observers can have relevance to the clinical task.
The argument for clinical relevance rests on the assumption that clinicians and non-clinicians have the same visual systems and perceptual and cognitive faculties that allow us to process and interpret stimuli.
Expertise changes the use of these faculties but does not create a new visual system.
Clinical relevance also requires that the artificial tasks and stimuli used capture the key elements of the clinical tasks and stimuli.
Going back to the work on prevalence effects, studying the effect of low prevalence on radiologists’ performance would require a series of reader studies of implausible length and duration.
Armed with this knowledge, it becomes possible to propose and test potential solutions to mitigate prevalence effects [@doi:10.1016/j.visres.2010.04.020; @doi:10.1167/9.1.31; @doi:10.3758/s13414-012-0354-4].
